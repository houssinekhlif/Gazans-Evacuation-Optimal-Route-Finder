{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe09725",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\21650\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'source'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     21\u001b[39m         G.add_edge(\n\u001b[32m     22\u001b[39m             row[\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     23\u001b[39m             row[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     24\u001b[39m             weight=row[weight_col]\n\u001b[32m     25\u001b[39m         )\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m G\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m G_humanitarian = \u001b[43mbuild_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43medges_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhumanitarian_w\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m G_risk         = build_graph(edges_df, \u001b[33m\"\u001b[39m\u001b[33mrisk_w\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m G_distance     = build_graph(edges_df, \u001b[33m\"\u001b[39m\u001b[33mdistance_w\u001b[39m\u001b[33m\"\u001b[39m)   \u001b[38;5;66;03m# may contain negative weights\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mbuild_graph\u001b[39m\u001b[34m(edges, weight_col)\u001b[39m\n\u001b[32m     19\u001b[39m G = nx.DiGraph()   \u001b[38;5;66;03m# directed is safer for route restrictions\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m edges.iterrows():\n\u001b[32m     21\u001b[39m     G.add_edge(\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msource\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     23\u001b[39m         row[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     24\u001b[39m         weight=row[weight_col]\n\u001b[32m     25\u001b[39m     )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\21650\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\21650\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\21650\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'source'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------------------------\n",
    "# LOAD DATA\n",
    "# ----------------------------------------------\n",
    "nodes_df = pd.read_csv(\"updated_nodes_with_intersections.csv\")\n",
    "edges_df = pd.read_csv(\"Edges.csv\")\n",
    "\n",
    "# Example column names (edit these if your files differ)\n",
    "# nodes_df columns: node_id, x, y\n",
    "# edges_df columns: source, target, humanitarian_w, risk_w, distance_w\n",
    "\n",
    "# ----------------------------------------------\n",
    "# BUILD GRAPHS FOR EACH SCENARIO\n",
    "# ----------------------------------------------\n",
    "def build_graph(edges, weight_col):\n",
    "    G = nx.DiGraph()   # directed is safer for route restrictions\n",
    "    for _, row in edges.iterrows():\n",
    "        G.add_edge(\n",
    "            row[\"source\"],\n",
    "            row[\"target\"],\n",
    "            weight=row[weight_col]\n",
    "        )\n",
    "    return G\n",
    "\n",
    "\n",
    "G_humanitarian = build_graph(edges_df, \"humanitarian_w\")\n",
    "G_risk         = build_graph(edges_df, \"risk_w\")\n",
    "G_distance     = build_graph(edges_df, \"distance_w\")   # may contain negative weights\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# SHORTEST PATH FUNCTION (chooses correct algorithm)\n",
    "# ----------------------------------------------\n",
    "def compute_shortest_path(G, source, target):\n",
    "    # Check for negative weights\n",
    "    has_negative = any(data['weight'] < 0 for _,_,data in G.edges(data=True))\n",
    "\n",
    "    if has_negative:\n",
    "        print(\"Negative weights detected → using Bellman–Ford\")\n",
    "        path = nx.bellman_ford_path(G, source, target, weight='weight')\n",
    "        length = nx.bellman_ford_path_length(G, source, target, weight='weight')\n",
    "    else:\n",
    "        print(\"No negative weights → using Dijkstra\")\n",
    "        path = nx.dijkstra_path(G, source, target, weight='weight')\n",
    "        length = nx.dijkstra_path_length(G, source, target, weight='weight')\n",
    "\n",
    "    return path, length\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# VISUALIZATION HELPERS\n",
    "# ----------------------------------------------\n",
    "def draw_graph(G, path):\n",
    "    pos = {row[\"node_id\"]: (row[\"x\"], row[\"y\"]) for _, row in nodes_df.iterrows()}\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Draw all nodes & edges\n",
    "    nx.draw(G, pos, node_size=30, edge_color='gray', alpha=0.6)\n",
    "\n",
    "    # Highlight shortest path\n",
    "    path_edges = list(zip(path, path[1:]))\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=path, node_color='red', node_size=80)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=path_edges, edge_color='red', width=2)\n",
    "\n",
    "    plt.title(\"Shortest Path\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# EXAMPLE USAGE\n",
    "# ----------------------------------------------\n",
    "source_node = 1\n",
    "target_node = 50  # change these\n",
    "\n",
    "# Scenario 1: maximize humanitarian aid access\n",
    "path_h, dist_h = compute_shortest_path(G_humanitarian, source_node, target_node)\n",
    "print(\"Humanitarian path:\", path_h, \"cost:\", dist_h)\n",
    "draw_graph(G_humanitarian, path_h)\n",
    "\n",
    "# Scenario 2: minimize risk\n",
    "path_r, dist_r = compute_shortest_path(G_risk, source_node, target_node)\n",
    "print(\"Risk path:\", path_r, \"cost:\", dist_r)\n",
    "draw_graph(G_risk, path_r)\n",
    "\n",
    "# Scenario 3: distance-based (may be negative → Bellman-Ford)\n",
    "path_d, dist_d = compute_shortest_path(G_distance, source_node, target_node)\n",
    "print(\"Distance path:\", path_d, \"cost:\", dist_d)\n",
    "draw_graph(G_distance, path_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c9da7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes loaded: (40, 6)\n",
      "Raw Excel shape: (0, 0)\n",
      "Warning: No empty separator column found. Assuming split after column 3.\n",
      "Final determined split index for Edges/Scenarios: 3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Edges table has only 0 columns. Expected 3 (Source, Target, Weight).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# -----------------------------------------------------\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# 4. ROBUST SPLIT AND HEADER ASSIGNMENT (NO CHANGES NEEDED HERE, IT'S CORRECT NOW)\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# -----------------------------------------------------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# The column assignment relies on the headers being correct from the Excel file\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# We rename them for use in the networkx part\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m edges_df.shape[\u001b[32m1\u001b[39m] < \u001b[32m3\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEdges table has only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medges_df.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns. Expected 3 (Source, Target, Weight).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m edges_df.columns = [\u001b[33m\"\u001b[39m\u001b[33mSource\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTarget\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWeight\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     69\u001b[39m edges_df[\u001b[33m\"\u001b[39m\u001b[33mSource\u001b[39m\u001b[33m\"\u001b[39m] = edges_df[\u001b[33m\"\u001b[39m\u001b[33mSource\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.strip()\n",
      "\u001b[31mValueError\u001b[39m: Edges table has only 0 columns. Expected 3 (Source, Target, Weight)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. LOAD NODES\n",
    "# -----------------------------------------------------\n",
    "try:\n",
    "    nodes_df = pd.read_csv(\"updated_nodes_with_intersections.csv\")\n",
    "    print(\"Nodes loaded:\", nodes_df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Nodes file not found. Please check filename.\")\n",
    "    exit()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. LOAD EXCEL (SIDE-BY-SIDE TABLES)\n",
    "# -----------------------------------------------------\n",
    "excel_file = \"your_edges_file.xlsx\"\n",
    "\n",
    "# Read without header first to accurately find the separator\n",
    "raw = pd.read_excel(excel_file, header=None)\n",
    "print(\"Raw Excel shape:\", raw.shape)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. ROBUST SPLIT (FIND EMPTY SEPARATOR COLUMN OR ASSUME WIDTH)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Find the first column that is completely empty (all NaNs)\n",
    "empty_cols = raw.columns[raw.isna().all()].tolist()\n",
    "\n",
    "# Define the expected number of columns for the edges table\n",
    "EXPECTED_EDGE_COLUMNS = 3 \n",
    "\n",
    "if not empty_cols:\n",
    "    # Scenario 1: No empty column found (tables are side-by-side)\n",
    "    # Assume the edges table is the first 3 columns, as expected.\n",
    "    split_index = EXPECTED_EDGE_COLUMNS \n",
    "    print(f\"Warning: No empty separator column found. Assuming split after column {split_index}.\")\n",
    "elif empty_cols[0] == 0:\n",
    "    # Scenario 2: The very first column is empty (highly unlikely for data)\n",
    "    # This might indicate a problem in the raw file read or a completely blank sheet.\n",
    "    raise ValueError(\"The first column of the Excel sheet appears empty. Check the sheet data.\")\n",
    "else:\n",
    "    # Scenario 3: Empty separator found at index > 0 (Success)\n",
    "    split_index = empty_cols[0]\n",
    "    # Check if the found split index is reasonable (at least 3 columns for edges)\n",
    "    if split_index < EXPECTED_EDGE_COLUMNS:\n",
    "        print(f\"Warning: Found separator at index {split_index}, but expected at least 3 edge columns. Assuming split is {EXPECTED_EDGE_COLUMNS}.\")\n",
    "        split_index = EXPECTED_EDGE_COLUMNS\n",
    "\n",
    "print(f\"Final determined split index for Edges/Scenarios: {split_index}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. ROBUST SPLIT AND HEADER ASSIGNMENT (NO CHANGES NEEDED HERE, IT'S CORRECT NOW)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. CLEAN DATA TYPES AND RENAME EDGE COLUMNS (UPDATED)\n",
    "# -----------------------------------------------------\n",
    "# Expecting: Source | Target | Weight\n",
    "# The column assignment relies on the headers being correct from the Excel file\n",
    "# We rename them for use in the networkx part\n",
    "\n",
    "if edges_df.shape[1] < 3:\n",
    "    raise ValueError(f\"Edges table has only {edges_df.shape[1]} columns. Expected 3 (Source, Target, Weight).\")\n",
    "\n",
    "edges_df.columns = [\"Source\", \"Target\", \"Weight\"]\n",
    "\n",
    "edges_df[\"Source\"] = edges_df[\"Source\"].astype(str).str.strip()\n",
    "edges_df[\"Target\"] = edges_df[\"Target\"].astype(str).str.strip()\n",
    "edges_df[\"Weight\"] = pd.to_numeric(edges_df[\"Weight\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. CREATE DATAFRAMES\n",
    "# -----------------------------------------------------\n",
    "# LEFT TABLE (Edges): Columns 0 to split_index\n",
    "edges_raw = raw.iloc[:, :split_index].copy()\n",
    "\n",
    "# RIGHT TABLE (Scenarios): Columns after split_index\n",
    "scenarios_raw = raw.iloc[:, split_index+1:].copy()\n",
    "\n",
    "# --- FIX HEADERS FOR LEFT TABLE ---\n",
    "edges_df = edges_raw.iloc[1:].copy() # Data starts at row 1\n",
    "edges_df.columns = edges_raw.iloc[0] # Header is row 0\n",
    "\n",
    "# --- FIX HEADERS FOR RIGHT TABLE ---\n",
    "scenarios_df = scenarios_raw.iloc[1:].copy() # Data starts at row 1\n",
    "scenarios_df.columns = scenarios_raw.iloc[0] # Header is row 0\n",
    "\n",
    "# Drop empty rows\n",
    "edges_df.dropna(how='all', inplace=True)\n",
    "scenarios_df.dropna(how='all', inplace=True)\n",
    "\n",
    "print(f\"Edges Table: {edges_df.shape}\")\n",
    "print(f\"Scenarios Table: {scenarios_df.shape}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. CLEAN DATA TYPES\n",
    "# -----------------------------------------------------\n",
    "# Standardize Edge Columns\n",
    "# We expect the first 3 columns to be Source, Target, Weight\n",
    "edges_df.columns = [\"Source\", \"Target\", \"Weight\"] \n",
    "\n",
    "edges_df[\"Source\"] = edges_df[\"Source\"].astype(str).str.strip()\n",
    "edges_df[\"Target\"] = edges_df[\"Target\"].astype(str).str.strip()\n",
    "edges_df[\"Weight\"] = pd.to_numeric(edges_df[\"Weight\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Standardize Scenario Columns\n",
    "# Assuming Right Table is: [Scenario Name, Coefficient]\n",
    "if scenarios_df.shape[1] >= 2:\n",
    "    scenarios_df.columns = [\"Scenario\", \"Coefficient\"]\n",
    "    scenarios_df[\"Coefficient\"] = pd.to_numeric(scenarios_df[\"Coefficient\"], errors=\"coerce\").fillna(0)\n",
    "else:\n",
    "    print(\"Warning: Scenarios table does not have 2 columns. Check Excel format.\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. BUILD GRAPH\n",
    "# -----------------------------------------------------\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes with error checking for missing columns in nodes CSV\n",
    "required_cols = [\"Name\", \"X\", \"Y\", \"Risk\", \"HumanitarianAid\", \"Type\"]\n",
    "for col in required_cols:\n",
    "    if col not in nodes_df.columns:\n",
    "        print(f\"Error: Node CSV missing column '{col}'\")\n",
    "        exit()\n",
    "\n",
    "for _, row in nodes_df.iterrows():\n",
    "    G.add_node(str(row[\"Name\"]).strip(), \n",
    "               x=row[\"X\"], \n",
    "               y=row[\"Y\"], \n",
    "               risk=pd.to_numeric(row[\"Risk\"], errors='coerce'),\n",
    "               humanitarian=pd.to_numeric(row[\"HumanitarianAid\"], errors='coerce'),\n",
    "               type=row[\"Type\"])\n",
    "\n",
    "# Add edges\n",
    "for _, row in edges_df.iterrows():\n",
    "    G.add_edge(row[\"Source\"], row[\"Target\"], weight=row[\"Weight\"])\n",
    "\n",
    "print(f\"Graph built: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7. RUN SCENARIOS\n",
    "# -----------------------------------------------------\n",
    "output_rows = []\n",
    "\n",
    "# Iterate through the Scenarios DataFrame (Rows, not columns)\n",
    "for _, row in scenarios_df.iterrows():\n",
    "    scen_name = row[\"Scenario\"]\n",
    "    coeff = row[\"Coefficient\"]\n",
    "\n",
    "    total_risk_score = 0\n",
    "    \n",
    "    for n in G.nodes:\n",
    "        # Safety check: ensure node has attributes (handle NaNs)\n",
    "        node_risk = G.nodes[n].get(\"risk\", 0) or 0\n",
    "        node_hum = G.nodes[n].get(\"humanitarian\", 0) or 0\n",
    "        \n",
    "        # Calculation logic\n",
    "        combined_val = (float(node_risk) * float(coeff)) + float(node_hum)\n",
    "        total_risk_score += combined_val\n",
    "\n",
    "    output_rows.append({\n",
    "        \"Scenario\": scen_name,\n",
    "        \"Coefficient\": coeff,\n",
    "        \"TotalMetric\": total_risk_score\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(output_rows)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 8. SAVE OUTPUT\n",
    "# -----------------------------------------------------\n",
    "try:\n",
    "    results_df.to_csv(\"scenario_results.csv\", index=False)\n",
    "    print(\"\\nSuccess! 'scenario_results.csv' saved.\")\n",
    "    print(results_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43eb4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# LOAD DATA\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(\"Edges.csv\")\n",
    "\n",
    "# Clean accidental unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# BUILD DIRECTED GRAPH\n",
    "# ---------------------------------------------------------\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add edges with all three weight types\n",
    "for _, row in df.iterrows():\n",
    "    G.add_edge(\n",
    "        row['From'],\n",
    "        row['To'],\n",
    "        risk_weight=float(row['danger weights']),\n",
    "        aid_weight=float(row['humanitarian weights']),\n",
    "        dist_weight=float(row['distance weights'])\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ALGORITHM SELECTOR\n",
    "# ---------------------------------------------------------\n",
    "def use_dijkstra(weight_type):\n",
    "    return nx.dijkstra_path(G, source_node, target_node, weight=weight_type)\n",
    "\n",
    "def use_bellman(weight_type):\n",
    "    return nx.bellman_ford_path(G, source_node, target_node, weight_type)\n",
    "\n",
    "def compute_path(source_node, target_node, mode):\n",
    "    \"\"\"\n",
    "    mode = \"risk\" → uses Dijkstra\n",
    "    mode = \"aid\"  → humanitarian priority → negative weights → Bellman–Ford\n",
    "    mode = \"distance\" → shortest distance → Dijkstra\n",
    "    \"\"\"\n",
    "\n",
    "    if mode == \"risk\":\n",
    "        weight_key = \"risk_weight\"\n",
    "        algorithm = \"dijkstra\"\n",
    "\n",
    "    elif mode == \"aid\":\n",
    "        weight_key = \"aid_weight\"\n",
    "        algorithm = \"bellman\"\n",
    "\n",
    "    elif mode == \"distance\":\n",
    "        weight_key = \"dist_weight\"\n",
    "        algorithm = \"dijkstra\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose: risk, aid, distance\")\n",
    "\n",
    "    print(f\"\\n➡ Mode selected: {mode.upper()}\")\n",
    "    print(f\"   Using algorithm: {algorithm}\")\n",
    "\n",
    "    try:\n",
    "        if algorithm == \"dijkstra\":\n",
    "            path = nx.dijkstra_path(G, source_node, target_node, weight=weight_key)\n",
    "            cost = nx.dijkstra_path_length(G, source_node, target_node, weight=weight_key)\n",
    "        else:\n",
    "            path = nx.bellman_ford_path(G, source_node, target_node, weight_key)\n",
    "            cost = nx.bellman_ford_path_length(G, source_node, target_node, weight_key)\n",
    "\n",
    "        return path, cost\n",
    "\n",
    "    except nx.NetworkXNoPath:\n",
    "        return None, None\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EXAMPLE: USER SELECTS THEIR CONDITION\n",
    "# ---------------------------------------------------------\n",
    "source_node = \"Beit Hanoun\"\n",
    "target_node = \"Rafah int\"\n",
    "\n",
    "user_condition = input(\"Choose your situation (risk / aid / distance): \").strip()\n",
    "\n",
    "path, total_cost = compute_path(source_node, target_node, user_condition)\n",
    "\n",
    "if path:\n",
    "    print(\"\\nOptimal Path Found:\")\n",
    "    print(\" → \".join(path))\n",
    "    print(f\"Total cost: {total_cost}\")\n",
    "else:\n",
    "    print(\"❌ No valid path found for this mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c240b22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Civilian nodes: ['Beit Hanoun', 'Beit Lahia', 'Jabalia', 'Atatra', 'Al-Shati', 'Rimal', 'Tuffah neighborhood park', \"Shuja'iyya\", 'Zeitoun', 'Sabra', 'Sheikh Radwan', 'Nuseirat', 'Bureij', 'Maghazi', 'Az Zawayda', 'Deir al Balah', 'Al Musaddar', 'Abasan al-Kabira', 'Abasan al-Saghira', 'Bani Suheila', \"Khuza'a\", 'Al Qarara', 'Al Fukhkhari', 'Rafah Camp', 'Tal as Sultan', 'مستشفي الخير', 'مدرسة الفاخورة']\n",
      "Destination nodes: ['مستشفى شهداء الاقصى', 'Gaza field hospital of the Jordanian-', 'مستشفى الشفا - مبنى الحروق', 'UNRWA vocational college', 'UNRWA-GFO', 'Al Quds Open University - Gaza Branch', 'جامعة الازهر كلية الحقوق المغراقة', 'Islamic University - khanyonuis']\n",
      "\n",
      ">>> Running scenario: RISK\n",
      "\n",
      ">>> Running scenario: AID\n",
      "\n",
      ">>> Running scenario: DISTANCE\n",
      "\n",
      "✅ All scenario CSVs generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# ===========================\n",
    "# 1. LOAD NODES\n",
    "# ===========================\n",
    "nodes_df = pd.read_csv(\"updated_nodes_with_intersections.csv\")\n",
    "\n",
    "# Clean column names\n",
    "nodes_df.columns = nodes_df.columns.str.strip()\n",
    "\n",
    "# Normalize type and name\n",
    "nodes_df[\"Type\"] = nodes_df[\"Type\"].str.lower().str.strip()\n",
    "nodes_df[\"Name\"] = nodes_df[\"Name\"].astype(str).str.strip()\n",
    "\n",
    "# ===========================\n",
    "# 2. LOAD EDGES\n",
    "# ===========================\n",
    "edges_df = pd.read_csv(\"Edges.csv\")\n",
    "edges_df = edges_df.loc[:, ~edges_df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Ensure numeric weights\n",
    "weight_cols = [\"danger weights\", \"humanitarian weights\", \"distance weights\"]\n",
    "for col in weight_cols:\n",
    "    edges_df[col] = pd.to_numeric(edges_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Clean node names\n",
    "edges_df['From'] = edges_df['From'].astype(str).str.strip()\n",
    "edges_df['To'] = edges_df['To'].astype(str).str.strip()\n",
    "\n",
    "# Shift negative weights to positive to avoid Bellman-Ford errors\n",
    "for col in weight_cols:\n",
    "    min_val = edges_df[col].min()\n",
    "    if min_val < 0:\n",
    "        edges_df[col] += abs(min_val) + 0.01  # small epsilon to avoid zero\n",
    "\n",
    "# ===========================\n",
    "# 3. BUILD GRAPH\n",
    "# ===========================\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add edges with all weights and make undirected\n",
    "for _, row in edges_df.iterrows():\n",
    "    for a, b in [(row['From'], row['To']), (row['To'], row['From'])]:\n",
    "        G.add_edge(a, b,\n",
    "                   risk=row['danger weights'],\n",
    "                   aid=row['humanitarian weights'],\n",
    "                   dist=row['distance weights'])\n",
    "\n",
    "# ===========================\n",
    "# 4. DETECT CIVILIAN & DESTINATION NODES\n",
    "# ===========================\n",
    "civilians = nodes_df[nodes_df[\"Type\"] == \"civilians\"][\"Name\"].tolist()\n",
    "destinations = nodes_df[nodes_df[\"Type\"] == \"destination\"][\"Name\"].tolist()\n",
    "\n",
    "print(\"Civilian nodes:\", civilians)\n",
    "print(\"Destination nodes:\", destinations)\n",
    "\n",
    "# ===========================\n",
    "# 5. PATH COMPUTATION FUNCTION\n",
    "# ===========================\n",
    "def compute_path(src, dst, weight_type):\n",
    "    \"\"\"\n",
    "    Computes shortest path from src to dst using Dijkstra.\n",
    "    Safely handles nodes not in graph.\n",
    "    \"\"\"\n",
    "    if src not in G or dst not in G:\n",
    "        return None, None, None\n",
    "\n",
    "    try:\n",
    "        path = nx.dijkstra_path(G, src, dst, weight=weight_type)\n",
    "        cost = nx.dijkstra_path_length(G, src, dst, weight=weight_type)\n",
    "        algo = \"dijkstra\"\n",
    "        return path, cost, algo\n",
    "    except nx.NetworkXNoPath:\n",
    "        return None, None, None\n",
    "\n",
    "# ===========================\n",
    "# 6. COMPUTE ALL PATHS\n",
    "# ===========================\n",
    "scenarios = {\n",
    "    \"risk\": \"risk\",\n",
    "    \"aid\": \"aid\",\n",
    "    \"distance\": \"dist\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for scenario, weight_col in scenarios.items():\n",
    "    print(f\"\\n>>> Running scenario: {scenario.upper()}\")\n",
    "    results = []\n",
    "\n",
    "    for src in civilians:\n",
    "        for dst in destinations:\n",
    "            path, cost, algo = compute_path(src, dst, weight_col)\n",
    "            results.append({\n",
    "                \"scenario\": scenario,\n",
    "                \"source\": src,\n",
    "                \"target\": dst,\n",
    "                \"path\": path,\n",
    "                \"cost\": cost,\n",
    "                \"algorithm\": algo,\n",
    "                \"note\": \"ok\" if path else \"no path\"\n",
    "            })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(f\"paths_results_{scenario}.csv\", index=False)\n",
    "    all_results.append(df_results)\n",
    "\n",
    "# ===========================\n",
    "# 7. COMBINE ALL SCENARIOS\n",
    "# ===========================\n",
    "final_df = pd.concat(all_results, ignore_index=True)\n",
    "final_df.to_csv(\"paths_results_all_scenarios.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ All scenario CSVs generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97457724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "PALESTINE SAFE ROUTE FINDER\n",
      "========================\n",
      "\n",
      "Select your starting location:\n",
      "1. Abasan al-Kabira\n",
      "2. Abasan al-Saghira\n",
      "3. Al Fukhkhari\n",
      "4. Al Musaddar\n",
      "5. Al Qarara\n",
      "6. Al Quds Open University - Gaza Branch\n",
      "7. Al-Shati\n",
      "8. Atatra\n",
      "9. Az Zawayda\n",
      "10. Bani Suheila\n",
      "11. Beit Hanoun\n",
      "12. Beit Lahia\n",
      "13. Bureij\n",
      "14. Deir al Balah\n",
      "15. Gaza field hospital of the Jordanian-\n",
      "16. Islamic University - khanyonuis\n",
      "17. Jabalia\n",
      "18. Khuza'a\n",
      "19. Maghazi\n",
      "20. Nuseirat\n",
      "21. Rafah Camp\n",
      "22. Rafah int\n",
      "23. Rimal\n",
      "24. Sabra\n",
      "25. Sheikh Radwan\n",
      "26. Shuja'iyya\n",
      "27. Tal as Sultan\n",
      "28. Tuffah neighborhood park\n",
      "29. UNRWA vocational college\n",
      "30. UNRWA-GFO\n",
      "31. Zeitoun\n",
      "32. gaza city int\n",
      "33. khan younes int\n",
      "34. middle camps int\n",
      "35. north gaza int\n",
      "36. جامعة الازهر كلية الحقوق المغراقة\n",
      "37. مدرسة الفاخورة\n",
      "38. مستشفى الشفا - مبنى الحروق\n",
      "39. مستشفى شهداء الاقصى\n",
      "40. مستشفي الخير\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nodes):\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m start_choice = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mEnter number: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m - \u001b[32m1\u001b[39m\n\u001b[32m     39\u001b[39m start_node = nodes[start_choice]\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mChoose your priority:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. LOAD DATA\n",
    "# -------------------------------------------------------\n",
    "df = pd.read_csv(\"Edges.csv\")\n",
    "\n",
    "# small cleanup\n",
    "df = df.dropna(subset=[\"From\", \"To\"])\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. BUILD GRAPH\n",
    "# -------------------------------------------------------\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    G.add_edge(\n",
    "        row[\"From\"],\n",
    "        row[\"To\"],\n",
    "        risk_weight=row[\"danger weights\"],\n",
    "        aid_weight=row[\"humanitarian weights\"],\n",
    "        distance_weight=row[\"distance weights\"]\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. USER INTERFACE\n",
    "# -------------------------------------------------------\n",
    "print(\"\\n========================\")\n",
    "print(\"PALESTINE SAFE ROUTE FINDER\")\n",
    "print(\"========================\\n\")\n",
    "\n",
    "print(\"Select your starting location:\")\n",
    "nodes = sorted(list(G.nodes()))\n",
    "for i, n in enumerate(nodes):\n",
    "    print(f\"{i+1}. {n}\")\n",
    "\n",
    "start_choice = int(input(\"\\nEnter number: \")) - 1\n",
    "start_node = nodes[start_choice]\n",
    "\n",
    "print(\"\\nChoose your priority:\")\n",
    "print(\"1. Avoid RISK (safest path)\")\n",
    "print(\"2. Seek HUMANITARIAN AID (injured case)\")\n",
    "print(\"3. Prioritise DISTANCE (fastest path)\")\n",
    "\n",
    "case_choice = int(input(\"\\nEnter number: \"))\n",
    "\n",
    "if case_choice == 1:\n",
    "    weight_type = \"risk_weight\"\n",
    "    print(\"\\n➡ Priority: Safety / Avoid risk\")\n",
    "elif case_choice == 2:\n",
    "    weight_type = \"aid_weight\"\n",
    "    print(\"\\n➡ Priority: Humanitarian Aid\")\n",
    "elif case_choice == 3:\n",
    "    weight_type = \"distance_weight\"\n",
    "    print(\"\\n➡ Priority: Distance\")\n",
    "else:\n",
    "    raise ValueError(\"Invalid choice!\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. CHOOSE ALGORITHM BASED ON WEIGHTS\n",
    "# -------------------------------------------------------\n",
    "# extract weights from graph\n",
    "weights = [data[weight_type] for u, v, data in G.edges(data=True)]\n",
    "\n",
    "use_bellmanford = any(w < 0 for w in weights)\n",
    "\n",
    "print(\"\\nSelected algorithm:\")\n",
    "if use_bellmanford:\n",
    "    print(\"➡ Bellman–Ford (negative weights detected)\")\n",
    "else:\n",
    "    print(\"➡ Dijkstra (all weights positive)\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5. CALCULATE SHORTEST PATHS\n",
    "# -------------------------------------------------------\n",
    "results = {}\n",
    "for target in nodes:\n",
    "    if target == start_node:\n",
    "        continue\n",
    "    try:\n",
    "        if use_bellmanford:\n",
    "            length, path = nx.single_source_bellman_ford(G, start_node, target, weight=weight_type)\n",
    "        else:\n",
    "            length = nx.dijkstra_path_length(G, start_node, target, weight=weight_type)\n",
    "            path = nx.dijkstra_path(G, start_node, target, weight=weight_type)\n",
    "\n",
    "        results[target] = (length, path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6. DISPLAY BEST DESTINATION\n",
    "# -------------------------------------------------------\n",
    "print(\"\\n========================\")\n",
    "print(\"Recommended Safe Destination\")\n",
    "print(\"========================\")\n",
    "\n",
    "best_dest = min(results, key=lambda x: results[x][0])\n",
    "best_cost, best_path = results[best_dest]\n",
    "\n",
    "print(f\"\\nBest Destination: {best_dest}\")\n",
    "print(f\"Total Cost: {best_cost:.3f}\")\n",
    "print(f\"Path: {' → '.join(best_path)}\")\n",
    "print(\"\\n========================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
